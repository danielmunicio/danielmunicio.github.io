<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Project 5: Diffusion Models</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      background: #f9f9f9;
      color: #333;
    }
    h1, h2, h3, h4, h5, h6 {
      text-align: center;
    }
    .desc {
      max-width: 900px;
      margin: auto;
      line-height: 1.6;
      text-align: center;
    }
    .image-container {
      text-align: center;
      margin: 30px auto;
      max-width: 1000px;
    }
    .image-container img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.2);
    }
    .image-container.small img {
      max-width: 500px;
    }
    .caption {
      margin-top: 10px;
      font-style: italic;
      color: #555;
    }
    .gallery {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin: 30px auto;
      max-width: 1200px;
    }
    .gallery-3col {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 20px;
      margin: 30px auto;
      max-width: 1200px;
    }
    .gallery .image-item {
      text-align: center;
      padding: 10px;
      background-color: #fff;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    .gallery .image-item img {
      width: 100%;
      height: auto;
      border-radius: 4px;
    }
    .gallery .image-caption {
      margin-top: 8px;
      font-size: 14px;
      color: #666;
      font-weight: 500;
    }
    table {
      margin: 30px auto;
      border-collapse: collapse;
      background: white;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    table td {
      padding: 15px;
      text-align: center;
      vertical-align: top;
    }
    table img {
      width: 256px;
      height: 256px;
      border-radius: 4px;
      display: block;
      margin: 0 auto;
    }
    table .img-caption {
      margin-top: 8px;
      font-size: 14px;
      color: #666;
      font-weight: 500;
    }
  </style>
</head>
<body>

<h1>Project 5: Diffusion Models</h1>

<h2>Part 0: Setup and Initial Prompts</h2>

<div class="desc">
  <p>I wrote custom text prompts and generated their embeddings using Jameson's provided Huggingface page, and I generated these images with random seed 100.</p>
</div>

<h3>Generated Images with Different Inference Steps</h3>

<table>
  <tr>
    <td><strong>Prompt</strong></td>
    <td><strong>6 Inference Steps</strong></td>
    <td><strong>20 Inference Steps</strong></td>
    <td><strong>40 Inference Steps</strong></td>
  </tr>
  <tr>
    <td><strong>"A dog catching a frisbee"</strong></td>
    <td>
      <img src="images/processed/dog_frisbee_part_1_1_6_inf_steps.png" alt="Dog Frisbee 6 steps">
    </td>
    <td>
      <img src="images/processed/dog_frisbee_part_1_1_20_inf_steps.png" alt="Dog Frisbee 20 steps">
    </td>
    <td>
      <img src="images/processed/dog_frisbee_part_1_1_40_inf_steps.png" alt="Dog Frisbee 40 steps">
    </td>
  </tr>
  <tr>
    <td><strong>"F1 race cars crossing the finish line"</strong></td>
    <td>
      <img src="images/processed/f1_race_finish_part_1_1_6_inf_steps.png" alt="F1 Race 6 steps">
    </td>
    <td>
      <img src="images/processed/f1_race_finish_part_1_1_20_inf_steps.png" alt="F1 Race 20 steps">
    </td>
    <td>
      <img src="images/processed/f1_race_finish_part_1_1_40_inf_steps.png" alt="F1 Race 40 steps">
    </td>
  </tr>
  <tr>
    <td><strong>"Marathon runners crossing the finish line"</strong></td>
    <td>
      <img src="images/processed/marathon_race_finish_part_1_1_6_inf_steps.png" alt="Marathon 6 steps">
    </td>
    <td>
      <img src="images/processed/marathon_race_finish_part_1_1_20_inf_steps.png" alt="Marathon 20 steps">
    </td>
    <td>
      <img src="images/processed/marathon_race_finish_part_1_1_40_inf_steps.png" alt="Marathon 40 steps">
    </td>
  </tr>
</table>

<div class="desc">
  <h4>Observations</h4>
  <p>The quality of the images improves a lot with more inference steps, but after a while, they just begin adding more details that aren't necessarily needed, while the 6-10 inference steps gap is much bigger, where it's actually meaningfully removing grain and noise still.</p>
</div>

<h2>Part 1: Sampling Loops</h2>

<h3>1.1 Implementing the Forward Process</h3>

<div class="desc">
  <p>The forward process adds noise to a clean image according to the equation:</p>
  <p><i>x<sub>t</sub> = √ᾱ<sub>t</sub> x<sub>0</sub> + √(1 - ᾱ<sub>t</sub>) ε</i></p>
  <p>where ε ~ N(0, 1) is Gaussian noise. I implemented this process and applied it to the Campanile
  test image at timesteps t = [250, 500, 750] to create progressively noisier versions.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_1/processed/noisy_campanile_t250.png" alt="Noisy Campanile t=250">
      <div class="img-caption">Noisy Campanile at t=250</div>
    </td>
    <td>
      <img src="output/part_1_1/processed/noisy_campanile_t500.png" alt="Noisy Campanile t=500">
      <div class="img-caption">Noisy Campanile at t=500</div>
    </td>
    <td>
      <img src="output/part_1_1/processed/noisy_campanile_t750.png" alt="Noisy Campanile t=750">
      <div class="img-caption">Noisy Campanile at t=750</div>
    </td>
  </tr>
</table>

<div class="desc">
  <p>As expected, the image becomes progressively noisier with higher timesteps. At t=250, the structure
  is still visible but degraded. At t=500, the image is heavily corrupted. At t=750, the image is almost
  pure noise.</p>
</div>

<h3>1.2 Classical Denoising</h3>

<div class="desc">
  <p>I attempted to denoise the noisy images using classical Gaussian blur filtering. As expected,
  this method struggles to recover the original image, especially at higher noise levels. The blur
  can reduce some noise but cannot recover the lost details.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_2/processed/campanille_gaussian_blur_t250_p1_2.png" alt="Gaussian Blur t=250">
      <div class="img-caption">Gaussian Blur Denoising at t=250</div>
    </td>
    <td>
      <img src="output/part_1_2/processed/campanille_gaussian_blur_t500_p1_2.png" alt="Gaussian Blur t=500">
      <div class="img-caption">Gaussian Blur Denoising at t=500</div>
    </td>
    <td>
      <img src="output/part_1_2/processed/campanille_gaussian_blur_t750_p1_2.png" alt="Gaussian Blur t=750">
      <div class="img-caption">Gaussian Blur Denoising at t=750</div>
    </td>
  </tr>
</table>

<h3>1.3 One-Step Denoising</h3>

<div class="desc">
  <p>Now I use the pretrained diffusion model UNet to denoise the images in a single step. The UNet
  estimates the noise in the image, which I then remove to recover an estimate of the original image.
  This uses the equation to predict x<sub>0</sub> from x<sub>t</sub> and the noise estimate ε.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_3/processed/part_1_3_t250.png" alt="One-Step Denoising t=250">
      <div class="img-caption">One-Step Denoised at t=250</div>
    </td>
    <td>
      <img src="output/part_1_3/processed/part_1_3_t500.png" alt="One-Step Denoising t=500">
      <div class="img-caption">One-Step Denoised at t=500</div>
    </td>
    <td>
      <img src="output/part_1_3/processed/part_1_3_t750.png" alt="One-Step Denoising t=750">
      <div class="img-caption">One-Step Denoised at t=750</div>
    </td>
  </tr>
</table>

<div class="desc">
  <p>The diffusion model performs significantly better than Gaussian blur! At t=250, the result is quite
  recognizable. At t=500, some structure is recovered but with artifacts. At t=750, the model struggles
  more with the heavy noise, but still produces something on the natural image manifold. The general shape is still recovered, but the image loses some of the finer details at the top of the campanile.</p>
</div>

<h3>1.4 Iterative Denoising</h3>

<div class="desc">
  <p>While one-step denoising works reasonably well for lower noise levels, diffusion models are designed
  to denoise iteratively. Instead of jumping directly from x<sub>t</sub> to x<sub>0</sub>, we gradually
  denoise through intermediate timesteps. I implemented iterative denoising using strided timesteps
  (starting at 990 with stride 30) and the DDPM denoising equation.</p>
</div>

<h4>Denoising Progression (Every 5th Step)</h4>

<div class="desc">
  <p>Starting from timestep 300 (i_start=10), showing every 5th denoising step:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_4/iterative_denoising_every_5th_step/processed/10th_image.png" alt="Step 10">
      <div class="img-caption">Step 10</div>
    </td>
    <td>
      <img src="output/part_1_4/iterative_denoising_every_5th_step/processed/15th_image.png" alt="Step 15">
      <div class="img-caption">Step 15</div>
    </td>
    <td>
      <img src="output/part_1_4/iterative_denoising_every_5th_step/processed/20th_image.png" alt="Step 20">
      <div class="img-caption">Step 20</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_4/iterative_denoising_every_5th_step/processed/25th_image.png" alt="Step 25">
      <div class="img-caption">Step 25</div>
    </td>
    <td>
      <img src="output/part_1_4/iterative_denoising_every_5th_step/processed/30th_image.png" alt="Step 30">
      <div class="img-caption">Step 30 (Final)</div>
    </td>
    <td></td>
  </tr>
</table>

<div class="desc">
  <p>We can see the image gradually becoming clearer and more detailed as we iterate through the denoising
  steps. The structure emerges first, followed by finer details.</p>
</div>

<h4>Comparison of Denoising Methods</h4>

<table>
  <tr>
    <td>
      <img src="output/part_1_4/processed/campanille_iterative_denoising_p1_4.png" alt="Iterative Denoising">
      <div class="img-caption">Iterative Denoising</div>
    </td>
    <td>
      <img src="output/part_1_4/processed/campanille_one_step_denoising_p1_4.png" alt="One-Step Denoising">
      <div class="img-caption">One-Step Denoising</div>
    </td>
    <td>
      <img src="output/part_1_4/processed/campanille_gaussian_denoising_p1_4.png" alt="Gaussian Blur">
      <div class="img-caption">Gaussian Blur</div>
    </td>
  </tr>
</table>

<div class="desc">
  <p>Iterative denoising produces the best results, with sharp details and accurate structure. One-step
  denoising is decent but lacks fine details. Gaussian blur completely fails to recover the image. This
  clearly demonstrates the power of iterative diffusion denoising.</p>
</div>

<h3>1.5 Diffusion Model Sampling</h3>

<div class="desc">
  <p>Now I use the iterative denoising function to generate images from scratch by starting with pure
  random noise (i_start=0). This demonstrates the model's ability to create new images from the learned
  distribution. I generated 5 samples using the prompt "a high quality photo".</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_5/processed/sample_1.png" alt="Sample 1">
      <div class="img-caption">Sample 1</div>
    </td>
    <td>
      <img src="output/part_1_5/processed/sample_2.png" alt="Sample 2">
      <div class="img-caption">Sample 2</div>
    </td>
    <td>
      <img src="output/part_1_5/processed/sample_3.png" alt="Sample 3">
      <div class="img-caption">Sample 3</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_5/processed/sample_4.png" alt="Sample 4">
      <div class="img-caption">Sample 4</div>
    </td>
    <td>
      <img src="output/part_1_5/processed/sample_5.png" alt="Sample 5">
      <div class="img-caption">Sample 5</div>
    </td>
    <td></td>
  </tr>
</table>

<div class="desc">
  <p>The images seem to be images, but they're not really of anything necessarily recognizable, and just seems like an image created pretty randomly.</p>
</div>

<h3>1.6 Classifier-Free Guidance (CFG)</h3>

<div class="desc">
  <p>To improve image quality, I implemented Classifier-Free Guidance (CFG). CFG computes both conditional
  and unconditional noise estimates, then extrapolates in the direction of the conditional estimate using
  the formula: ε = ε<sub>u</sub> + γ(ε<sub>c</sub> - ε<sub>u</sub>). I used γ=7 for these results.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_6/processed/sample_cfg_1.png" alt="CFG Sample 1">
      <div class="img-caption">CFG Sample 1</div>
    </td>
    <td>
      <img src="output/part_1_6/processed/sample_cfg_2.png" alt="CFG Sample 2">
      <div class="img-caption">CFG Sample 2</div>
    </td>
    <td>
      <img src="output/part_1_6/processed/sample_cfg_3.png" alt="CFG Sample 3">
      <div class="img-caption">CFG Sample 3</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_6/processed/sample_cfg_4.png" alt="CFG Sample 4">
      <div class="img-caption">CFG Sample 4</div>
    </td>
    <td>
      <img src="output/part_1_6/processed/sample_cfg_5.png" alt="CFG Sample 5">
      <div class="img-caption">CFG Sample 5</div>
    </td>
    <td></td>
  </tr>
</table>

<div class="desc">
  <p>With CFG, the image quality improves dramatically! The results are much sharper, more detailed, and
  more coherent compared to sampling without guidance. The objects are more clearly defined and the overall
  composition is better. This demonstrates the significant impact of classifier-free guidance on generation
  quality.</p>
</div>

<h3>1.7 Image-to-image Translation</h3>

<div class="desc">
  <p>In this section, I explored SDEdit-style image-to-image translation. By adding noise to a real image
  and then denoising it with CFG, we can create variations of the image. The amount of noise determines how
  much the output deviates from the original - lower noise levels preserve more of the original structure,
  while higher noise levels allow for more creative variation.</p>
</div>

<h4>Campanile Image-to-Image Translation</h4>

<table>
  <tr>
    <td>
      <img src="output/part_1_7/web_image_i_start_1.png" alt="i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7/web_image_i_start_3.png" alt="i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7/web_image_i_start_5.png" alt="i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7/web_image_i_start_7.png" alt="i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7/web_image_i_start_10.png" alt="i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7/web_image_i_start_20.png" alt="i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
</table>

<div class="desc">
  <p>As expected, with lower i_start values (less noise), the output closely resembles the original
  Campanile. As we increase i_start (more noise), the model has more freedom to deviate from the original
  while still maintaining some structural similarity.</p>
</div>

<h4>Additional Test Images</h4>

<h5>LeBron Fadeaway</h5>
<table>
  <tr>
    <td>
      <img src="output/part_1_7/lebron_i_start_1.png" alt="LeBron i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7/lebron_i_start_3.png" alt="LeBron i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7/lebron_i_start_5.png" alt="LeBron i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7/lebron_i_start_7.png" alt="LeBron i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7/lebron_i_start_10.png" alt="LeBron i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7/lebron_i_start_20.png" alt="LeBron i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
  <tr>
    <td colspan="3" style="text-align: center;">
      <img src="output/part_1_7/lebron_fadeaway_original.jpg" alt="Original LeBron Fadeaway" style="width: 256px;">
      <div class="img-caption">Original LeBron Fadeaway</div>
    </td>
  </tr>
</table>

<h5>Tom Brady</h5>
<table>
  <tr>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_1.png" alt="Tom Brady i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_3.png" alt="Tom Brady i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_5.png" alt="Tom Brady i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_7.png" alt="Tom Brady i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_10.png" alt="Tom Brady i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7/tom_brady_i_start_20.png" alt="Tom Brady i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
</table>

<h4>1.7.1 Editing Hand-Drawn and Web Images</h4>

<div class="desc">
  <p>The SDEdit procedure works particularly well when starting with non-realistic images like sketches
  or drawings. By projecting these onto the natural image manifold, we can transform simple drawings into
  realistic photos while preserving the overall composition.</p>
</div>

<h5>Web Image of Guy Locking In</h5>

<div class="desc">
  <p>I found a web image and applied the same noise and denoising procedure at different
  noise levels:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_1.png" alt="Web i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_3.png" alt="Web i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_5.png" alt="Web i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_7.png" alt="Web i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_10.png" alt="Web i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/web_image/web_image_i_start_20.png" alt="Web i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
  <tr>
    <td colspan="3" style="text-align: center;">
      <img src="output/part_1_7_1_web/web_image/start_image.png" alt="Original Web Image of Guy Locking In" style="width: 256px;">
      <div class="img-caption">Original Web Image</div>
    </td>
  </tr>
</table>

<h5>Hand-Drawn Image 1: Car</h5>

<div class="desc">
  <p>I drew a simple car sketch and applied the SDEdit procedure to transform it into a realistic image:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_1.png" alt="Car i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_3.png" alt="Car i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_5.png" alt="Car i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_7.png" alt="Car i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_10.png" alt="Car i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_car/hand_drawn_car_i_start_20.png" alt="Car i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
  <tr>
    <td colspan="3" style="text-align: center;">
      <img src="output/part_1_7_1_web/hand_drawn_car/car_drawing.png" alt="Original Car Drawing" style="width: 256px;">
      <div class="img-caption">Original Hand-Drawn Car</div>
    </td>
  </tr>
</table>

<h5>Hand-Drawn Image 2: Cat</h5>

<div class="desc">
  <p>I drew a simple cat sketch and applied the same procedure:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_1.png" alt="Cat i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_3.png" alt="Cat i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_5.png" alt="Cat i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_7.png" alt="Cat i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_10.png" alt="Cat i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_1_web/hand_drawn_cat/hand_drawn_cat_i_start_20.png" alt="Cat i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
  <tr>
    <td colspan="3" style="text-align: center;">
      <img src="output/part_1_7_1_web/hand_drawn_cat/drawn_cat_image.png" alt="Original Cat Drawing" style="width: 256px;">
      <div class="img-caption">Original Hand-Drawn Cat</div>
    </td>
  </tr>
</table>

<div class="desc">
  <h4>Observations on Hand-Drawn Images</h4>
  <p>My hand-drawn images were generally so bad, that the model couldn't create a realistic version of the car or cat that I drew, but it's still interesting to see what it came up with from those drawings.</p>
</div>

<h4>1.7.2 Inpainting</h4>

<div class="desc">
  <p>Following the RePaint paper, I implemented inpainting by combining the diffusion denoising process
  with masked replacement. At each denoising step, after obtaining x_t, I replace the unmasked regions
  with the appropriately noised original image. This allows the model to fill in holes or edit specific
  regions while preserving the rest of the image.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_2/campanile.png" alt="Campanile Inpainted">
      <div class="img-caption">Campanile Inpainted</div>
    </td>
    <td>
      <img src="output/part_1_7_2/tom_brady_throwing_pie.png" alt="Tom Brady Throwing Pie">
      <div class="img-caption">Tom Brady Throwing a Pie</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_2/tom_brady_throwing_watermelon.png" alt="Tom Brady Throwing Watermelon">
      <div class="img-caption">Tom Brady Throwing a Watermelon</div>
    </td>
    <td>
      <img src="output/part_1_7_2/lebron_shooting_watermelon.png" alt="LeBron Shooting Pumpkin">
      <div class="img-caption">LeBron Shooting a Pumpkin</div>
    </td>
  </tr>
</table>

<h4>1.7.3 Text-Conditional Image-to-image Translation</h4>

<div class="desc">
  <p>Now I extend the SDEdit procedure by using text prompts to guide the image generation. Instead of
  using the generic prompt "a high quality photo", I use specific text prompts that describe what I want
  the image to become. This gives us control over the creative direction while still preserving some
  structure from the original image.</p>
</div>

<h5>Campanile with "A Rocket Ship" Prompt</h5>

<div class="desc">
  <p>I applied the text-conditional SDEdit with the prompt "a rocket ship" to transform the Campanile
  into a rocket ship at various noise levels:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_1.png" alt="Rocket i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_3.png" alt="Rocket i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_5.png" alt="Rocket i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_7.png" alt="Rocket i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_10.png" alt="Rocket i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_3/campanille_rocket_image_i_start_20.png" alt="Rocket i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
</table>

<div class="desc">
  <p>With lower noise levels, the rocket ship retains the verticalness and structure of the Campanile. But by i_start=5, the rocket generally doesn't really retain anything of the original scene, except maybe the sky and surrounding scenery, but generally loses a lot of the original image.</p>
</div>

<h5>LeBron with "A Photo of a Man" Prompt</h5>

<div class="desc">
  <p>I applied the text-conditional SDEdit with the prompt "a photo of a man" to the LeBron fadeaway image:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_1.png" alt="LeBron Man i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_3.png" alt="LeBron Man i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_5.png" alt="LeBron Man i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_7.png" alt="LeBron Man i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_10.png" alt="LeBron Man i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_3/lebron_with_prompt_a_photo_of_a_man_image_i_start_20.png" alt="LeBron Man i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
</table>

<h5>Tom Brady with "A Photo of a Man" Prompt</h5>

<div class="desc">
  <p>I applied the same text-conditional SDEdit with the prompt "a photo of a man" to the Tom Brady image:</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_1.png" alt="Tom Man i_start=1">
      <div class="img-caption">i_start=1</div>
    </td>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_3.png" alt="Tom Man i_start=3">
      <div class="img-caption">i_start=3</div>
    </td>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_5.png" alt="Tom Man i_start=5">
      <div class="img-caption">i_start=5</div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_7.png" alt="Tom Man i_start=7">
      <div class="img-caption">i_start=7</div>
    </td>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_10.png" alt="Tom Man i_start=10">
      <div class="img-caption">i_start=10</div>
    </td>
    <td>
      <img src="output/part_1_7_3/tom_with_prompt_a_photo_of_a_man_image_i_start_20.png" alt="Tom Man i_start=20">
      <div class="img-caption">i_start=20</div>
    </td>
  </tr>
</table>

<h3>1.8 Visual Anagrams</h3>

<div class="desc">
  <p>Visual anagrams are optical illusions created with diffusion models. An image appears to depict one scene
  when viewed normally, but reveals a completely different scene when flipped upside down. This is achieved by
  averaging the noise estimates from two different prompts - one for the normal orientation and one for the
  flipped orientation.</p>

  <p>The algorithm works as follows: At each denoising step, we denoise the image normally with prompt p<sub>1</sub>
  to get noise estimate ε<sub>1</sub>. Simultaneously, we flip the image upside down, denoise with prompt
  p<sub>2</sub> to get ε<sub>2</sub>, flip ε<sub>2</sub> back, and average the two noise estimates:
  ε = (ε<sub>1</sub> + ε<sub>2</sub>) / 2. This composite noise estimate guides the diffusion process to create
  an image that satisfies both prompts in their respective orientations.</p>
</div>

<h4>Visual Anagram 1: Old Man / People Around Campfire</h4>

<div class="desc">
  <p>This illusion shows "an oil painting of an old man" when viewed normally, but reveals "an oil painting of
  people around a campfire" when flipped upside down.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_8/visual_anagram_campfire_oldman_normal.png" alt="An Oil Painting of an Old Man">
      <div class="img-caption">An Oil Painting of an Old Man</div>
    </td>
    <td>
      <img src="output/part_1_8/visual_anagram_campfire_oldman_flipped.png" alt="An Oil Painting of People Around a Campfire">
      <div class="img-caption">An Oil Painting of People Around a Campfire (Flipped)</div>
    </td>
  </tr>
</table>

<h4>Visual Anagram 2: Man Wearing a Hat / Amalfi Coast</h4>

<div class="desc">
  <p>This illusion shows "a man wearing a hat" when viewed normally, but reveals "the Amalfi Coast"
  when flipped upside down.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_8/visual_anagram_almafi_coast_waterfalls_normal.png" alt="A Man Wearing a Hat">
      <div class="img-caption">A Man Wearing a Hat</div>
    </td>
    <td>
      <img src="output/part_1_8/visual_anagram_almafi_coast_waterfalls_flipped.png" alt="The Amalfi Coast">
      <div class="img-caption">The Amalfi Coast (Flipped)</div>
    </td>
  </tr>
</table>

<h3>1.9 Hybrid Images</h3>

<div class="desc">
  <p>Following the Factorized Diffusion approach, I created hybrid images using diffusion models. Similar to
  Project 2, hybrid images combine low-frequency content from one image with high-frequency content from another.
  When viewed close up, you see the high-frequency details, but from far away, the low-frequency content dominates.</p>

  <p>The algorithm: At each denoising step, we compute two noise estimates using different prompts: ε<sub>1</sub>
  from prompt p<sub>1</sub> and ε<sub>2</sub> from prompt p<sub>2</sub>. We then apply frequency separation:
  ε = f<sub>lowpass</sub>(ε<sub>1</sub>) + f<sub>highpass</sub>(ε<sub>2</sub>). This combines the low frequencies
  of the first prompt with the high frequencies of the second prompt. I used a Gaussian blur with kernel size 33
  and sigma 2 for the low-pass filter.</p>
</div>

<h4>Hybrid Image 1: Skull / Waterfall</h4>

<div class="desc">
  <p>This hybrid image combines "a lithograph of a skull" (high frequencies) with "a lithograph of a waterfall"
  (low frequencies). View it close up to see the skull, or zoom out / step back to see the waterfall.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_9/skull_waterfall.png" alt="Hybrid: Skull and Waterfall">
      <div class="img-caption">Hybrid Image: Skull (close) / Waterfall (far)</div>
    </td>
  </tr>
</table>

<h4>Hybrid Image 2: Rocket Ship / Pencil</h4>

<div class="desc">
  <p>This hybrid image combines "a rocket ship" (high frequencies) with "a pencil" (low frequencies). The vertical
  structure works well for both objects at different frequencies.</p>
</div>

<table>
  <tr>
    <td>
      <img src="output/part_1_9/rocket_ship_and_pencil_2.png" alt="Hybrid: Rocket Ship and Pencil">
      <div class="img-caption">Hybrid Image: Rocket Ship (close) / Pencil (far)</div>
    </td>
  </tr>
</table>

</body>
</html>

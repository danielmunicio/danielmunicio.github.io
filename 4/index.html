<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Project 4: Neural Radiance Field (NeRF)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      background: #f9f9f9;
      color: #333;
    }
    h1, h2, h3 {
      text-align: center;
    }
    .desc {
      max-width: 900px;
      margin: auto;
      line-height: 1.6;
      text-align: center;
    }
    .image-container {
      text-align: center;
      margin: 30px auto;
      max-width: 1000px;
    }
    .image-container img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.2);
    }
    .image-container.small img {
      max-width: 500px;
    }
    .caption {
      margin-top: 10px;
      font-style: italic;
      color: #555;
    }
    .gallery {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
      gap: 30px;
      margin: 30px auto;
      max-width: 1200px;
    }
    .gallery .image-container {
      margin: 0;
    }
    .training-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 15px;
      margin: 30px auto;
      max-width: 1200px;
    }
    .training-grid-2x4 {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 15px;
      margin: 30px auto;
      max-width: 1200px;
    }
    .training-step {
      text-align: center;
      padding: 10px;
      background-color: #fff;
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    .training-step img {
      width: 100%;
      height: auto;
      border-radius: 4px;
    }
    .training-step .step-caption {
      margin-top: 8px;
      font-size: 14px;
      color: #666;
      font-weight: 500;
    }
  </style>
</head>
<body>

<h1>Project 4: Neural Radiance Field (NeRF)</h1>

<h2>Part 0: Camera Calibration and 3D Scanning</h2>

<h3>The Object: A Mini Catrina</h3>

<div class="desc">
  <p>I used a mini <strong>Catrina</strong> sculpture (a traditional Day of the Dead figure) for my dataset.
  Photographed it with an ArUco tag for camera calibration.</p>
</div>

<div class="image-container small">
  <img src="images/IMG_4889.jpg" alt="Mini Catrina Sculpture">
  <div class="caption">Mini Catrina sculpture with ArUco tag</div>
</div>

<h3>Camera Frustum Visualizations</h3>

<div class="desc">
  <p>Camera poses estimated from ArUco tag detection, visualized in Viser:</p>
</div>

<div class="gallery">
  <div class="image-container">
    <img src="images/viser_viz.png" alt="Viser Visualization 1">
    <div class="caption">Camera frustums visualization - View 1</div>
  </div>
  <div class="image-container">
    <img src="images/viser_vis_2.png" alt="Viser Visualization 2">
    <div class="caption">Camera frustums visualization - View 2</div>
  </div>
</div>

<h2>Part 1: Fit a Neural Field to a 2D Image</h2>

<div class="desc">
  <p>Before jumping into 3D, I implemented a simpler 2D neural field that maps pixel coordinates (u, v) to RGB colors.
  Uses an MLP with sinusoidal positional encoding so it can learn high-frequency details.</p>
</div>

<h3>Model Architecture</h3>

<div class="desc">
  <p><strong>Network:</strong> 4-layer MLP with width 256, ReLU activations, Sigmoid output. Again, just copied the spec.</p>
  <p><strong>Positional Encoding:</strong> L=10 frequency levels, expanding (u,v) coordinates to 42 dimensions</p>
  <p><strong>Training:</strong> Adam with lr=1e-2, MSE loss, 3000 iterations, batch size 10k pixels</p>
</div>

<h3>Training Progression</h3>

<div class="desc">
  <p>Watching the model learn the fox image over 2500 iterations:</p>
</div>

<div class="training-grid">
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_0000.png" alt="Iteration 0">
    <div class="step-caption">Iteration 0</div>
  </div>
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_0500.png" alt="Iteration 500">
    <div class="step-caption">Iteration 500</div>
  </div>
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_1000.png" alt="Iteration 1000">
    <div class="step-caption">Iteration 1,000</div>
  </div>
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_1500.png" alt="Iteration 1500">
    <div class="step-caption">Iteration 1,500</div>
  </div>
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_2000.png" alt="Iteration 2000">
    <div class="step-caption">Iteration 2,000</div>
  </div>
  <div class="training-step">
    <img src="images/part1_results/checkpoint_iter_2500.png" alt="Iteration 2500">
    <div class="step-caption">Iteration 2,500</div>
  </div>
</div>

<h3>PSNR Training Curve</h3>

<div class="desc">
  <p>PSNR improving over time as the model learns:</p>
</div>

<div class="image-container">
  <img src="images/part1_results/psnr_curve.png" alt="PSNR Training Curve">
  <div class="caption">PSNR curve</div>
</div>

<h3>Hyperparameter Study</h3>

<div class="desc">
  <p>Comparing different positional encoding frequencies (L) and network widths. Low L gives blurry results (can't capture
  high-frequency details), and low width limits what the network can learn. You need both to be high for good results:</p>
</div>

<div class="image-container">
  <img src="images/part1_results/hyperparameter_comparison_2x2.png" alt="Hyperparameter Comparison">
  <div class="caption">L={2, 10} × Width={64, 256} comparison</div>
</div>

<h3>Final Comparison</h3>

<div class="image-container">
  <img src="images/part1_results/final_comparison.png" alt="Final Reconstruction Comparison">
  <div class="caption">Original image vs. reconstructed image vs. absolute difference</div>
</div>

<h2>Part 2: Fit a Neural Radiance Field from Multi-View Images</h2>

<div class="desc">
  <p>Here I trained a NeRF model on the Lego dataset. NeRF represents a 3D scene as a continuous
  function that maps 3D coordinates and viewing directions to colors and densities.</p>
</div>

<h3>Implementation Overview</h3>

<div class="desc">
  <p><strong>Ray Generation:</strong> For each pixel, I compute a ray origin (camera position) and direction
  by transforming pixel coordinates through the inverse camera intrinsics and then to world space.</p>

  <p><strong>Point Sampling:</strong> I sample 64 points along each ray between near=2.0 and far=6.0 planes,
  with random perturbations during training.</p>

  <p><strong>Neural Network:</strong> I basically just copied the model architecture from the spec - an 8-layer
  MLP with width 256, using sinusoidal positional encoding (L=10 for positions, L=4 for directions). Nothing
  fancy here, just the standard NeRF setup with ReLU activations, Sigmoid for RGB, and ReLU for density.</p>

  <p><strong>Volume Rendering:</strong> Standard volume rendering equation to composite colors along each ray,
  comparing to ground truth with MSE loss.</p>

  <p><strong>Training:</strong> Adam optimizer with lr=5e-4, batch size 10,000 rays, trained until PSNR > 23 dB.</p>
</div>

<h3>Lego Dataset Visualizations</h3>

<div class="desc">
  <p>Camera poses and ray sampling visualizations. Left shows rays from one camera, right shows multiple cameras:</p>
</div>

<div class="gallery">
  <div class="image-container">
    <img src="images/viser_single_camera_many_rays.png" alt="Single Camera Ray Visualization">
    <div class="caption">Single camera with multiple rays</div>
  </div>
  <div class="image-container">
    <img src="images/viser_many_camera_rays.png" alt="Multiple Camera Ray Visualization">
    <div class="caption">Multiple cameras with rays</div>
  </div>
</div>

<h3>Training Progression</h3>

<div class="desc">
  <p>The model goes from complete noise to something recognizable pretty quickly in the first few hundred steps.
  Most of the learning happens early on - by step 500 you can already tell it's a bulldozer. After that it's
  mostly refinement. You'll notice there's not much visible difference between steps 5000 and 10,000; the model
  had basically converged by then.</p>
</div>

<div class="training-grid">
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0000.png" alt="Step 0">
    <div class="step-caption">Step 0</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0100.png" alt="Step 100">
    <div class="step-caption">Step 100</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0200.png" alt="Step 200">
    <div class="step-caption">Step 200</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0300.png" alt="Step 300">
    <div class="step-caption">Step 300</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0400.png" alt="Step 400">
    <div class="step-caption">Step 400</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_0500.png" alt="Step 500">
    <div class="step-caption">Step 500</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_1000.png" alt="Step 1000">
    <div class="step-caption">Step 1000</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_2000.png" alt="Step 2000">
    <div class="step-caption">Step 2000</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_5000.png" alt="Step 5000">
    <div class="step-caption">Step 5000</div>
  </div>
  <div class="training-step">
    <img src="images/lego_render_images/render_step_10000.png" alt="Step 10000">
    <div class="step-caption">Step 10,000</div>
  </div>
</div>

<h3>Training Metrics</h3>

<div class="desc">
  <p>PSNR (higher is better) steadily increases during training, eventually plateauing around 23-24 dB.</p>
</div>

<div class="image-container">
  <img src="images/PSNR_Plot_Lego_Set.png" alt="PSNR Training Curve">
  <div class="caption">PSNR over training iterations</div>
</div>

<h3>Novel View Synthesis</h3>

<div class="desc">
  <p>Here's a 360° rotation around the scene from viewpoints the model never saw during training.
  Pretty cool that it can synthesize these new views!</p>
</div>

<div class="image-container">
  <img src="images/lego_novel_view.gif" alt="Novel View Synthesis - 360° Rotation">
  <div class="caption">Novel view synthesis showing a complete 360° rotation around the Lego scene</div>
</div>

<h2>Part 2.6: Training with My Own Data</h2>

<div class="desc">
  <p>I trained a NeRF on my Catrina photos from Part 0.</p>
</div>

<h3>Novel View Synthesis</h3>

<div class="image-container">
  <img src="images/custom_nerf_rotation.gif" alt="Custom NeRF - 360° Rotation">
  <div class="caption">360° rotation around my custom object</div>
</div>

<h3>Code and Hyperparameter Changes</h3>

<div class="desc">
  <p>A few things I had to adjust for my own data:</p>

  <p><strong>Camera Intrinsics:</strong> My iPhone camera doesn't have square pixels (fx ≠ fy), so I used
  the actual focal lengths from camera calibration instead of the Lego dataset's simplified fx = fy assumption.</p>

  <p><strong>Near/Far Planes:</strong> I did some quick EDA on my camera positions to figure out reasonable
  depth bounds. Ended up using near=0.15 and far=0.85 (compared to Lego's 2.0/6.0) since my object is much
  closer to the camera.</p>

  <p><strong>Image Downsampling:</strong> I had to heavily downsample my iPhone photos so this would actually
  render sometime in my lifetime. Training on full-res images would've taken forever.</p>

  <p><strong>Extended Training:</strong> Trained for 50,000 iterations instead of 10,000. The real-world scene
  is messier and needed more time to converge.</p>

  <p><strong>Learning Rate:</strong> Kept the same lr=5e-4 and Adam optimizer - no need to change what works.</p>
</div>

<h3>Training Progress</h3>

<div class="desc">
  <p>Training loss over time:</p>
</div>

<div class="image-container">
  <img src="images/training_loss_plot.png" alt="Training Loss Curve">
  <div class="caption">Training loss over iterations</div>
</div>

<h3>Intermediate Training Results</h3>

<div class="desc">
  <p>Snapshots during training showing the model slowly figuring out what the Catrina looks like:</p>
</div>

<div class="training-grid-2x4">
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_0000.png" alt="Step 0">
    <div class="step-caption">Step 0</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_0100.png" alt="Step 100">
    <div class="step-caption">Step 100</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_0500.png" alt="Step 500">
    <div class="step-caption">Step 500</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_1000.png" alt="Step 1000">
    <div class="step-caption">Step 1,000</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_5000.png" alt="Step 5000">
    <div class="step-caption">Step 5,000</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_10000.png" alt="Step 10000">
    <div class="step-caption">Step 10,000</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_25000.png" alt="Step 25000">
    <div class="step-caption">Step 25,000</div>
  </div>
  <div class="training-step">
    <img src="images/katrina_render_images/render_step_50000.png" alt="Step 50000">
    <div class="step-caption">Step 50,000</div>
  </div>
</div>

</body>
</html>
